services:
  ollama:
    image: ${OLLAMA_IMAGE:-ollama/ollama:latest}
    container_name: ollama
    restart: unless-stopped
    expose:
      - "11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - backend-net
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  caddy:
    image: ${CADDY_IMAGE:-caddy:2.10}
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/conf:/etc/caddy
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - backend-net
    depends_on:
      openwebui:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:2019/metrics || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s

  openwebui:
    image: ${OPENWEBUI_IMAGE:-ghcr.io/open-webui/open-webui:main}
    container_name: openwebui
    restart: unless-stopped
    expose:
      - "8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-your-secret-key}
    volumes:
      - ./openwebui/data:/app/backend/data
    networks:
      - backend-net
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
networks:
  backend-net:
    driver: bridge

volumes:
  ollama_data:
    name: ollama_data
  caddy_data:
    name: candy_data
  caddy_config:
    name: candy_conf
