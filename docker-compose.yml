name: rpi5-openwebui

# Переиспользуемые конфигурации
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "1m"
    max-file: "1"

services:
  ollama:
    image: ${OLLAMA_IMAGE:-ollama/ollama:latest}
    container_name: ollama
    restart: unless-stopped
    expose:
      - "11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - backend-net
    healthcheck:
      test: [ "CMD-SHELL", "ollama list || exit 1" ]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 4G

  caddy:
    image: ${CADDY_IMAGE:-caddy:2.10}
    container_name: caddy
    restart: unless-stopped
    environment:
      - SEARXNG_BASE_URL=${SEARXNG_BASE_URL:-search.localhost}
      - OPENWEBUI_HOSTNAME=${OPENWEBUI_HOSTNAME:-ai.localhost}
      - CLIPROXY_HOSTNAME=${CLIPROXY_HOSTNAME:-proxy.localhost}
      - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/config:/etc/caddy
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - backend-net
    depends_on:
      openwebui:
        condition: service_healthy
      searxng:
        condition: service_healthy
      cli-proxy-api-plus:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://caddy:2019/metrics || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 256M

  openwebui:
    image: ${OPENWEBUI_IMAGE:-ghcr.io/open-webui/open-webui:main}
    container_name: openwebui
    restart: unless-stopped
    expose:
      - "8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - ENABLE_CORS=${ENABLE_CORS:-false}
      - CORS_ALLOW_ORIGIN=${CORS_ALLOW_ORIGIN:-*}
    volumes:
      - ./openwebui/data:/app/backend/data
    networks:
      - backend-net
    depends_on:
      ollama:
        condition: service_healthy
      cli-proxy-api-plus:
        condition: service_healthy
      searxng:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  valkey:
    container_name: valkey
    image: docker.io/valkey/valkey:9.0.1-alpine3.23
    command: valkey-server --save 30 1 --loglevel warning
    restart: unless-stopped
    networks:
      - backend-net
    volumes:
      - valkey_data:/data
    logging: *default-logging
    healthcheck:
      test: [ "CMD", "valkey-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    deploy:
      resources:
        limits:
          memory: 128M

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - backend-net
    expose:
      - "8080"
    volumes:
      - ./searxng/config:/etc/searxng:rw
      - searxng_data:/var/cache/searxng:rw
    environment:
      - LANG=C.UTF-8
      - LC_ALL=C.UTF-8
      - SEARXNG_PUBLIC_INSTANCE=${SEARXNG_PUBLIC_INSTANCE:-false}
      - SEARXNG_LIMITER=${SEARXNG_LIMITER:-true}
      - SEARXNG_BASE_URL=https://search.${SEARXNG_BASE_URL:-search.localhost}/
      - SEARXNG_IMAGE_PROXY=${SEARXNG_IMAGE_PROXY:-false}
      - SEARXNG_SECRET=${SEARXNG_SECRET}
      - SEARXNG_VALKEY_URL=${SEARXNG_VALKEY_URL:-valkey://valkey:6379/0}
      - SEARXNG_DEBUG=${SEARXNG_DEBUG:-false}
      - SEARXNG_PORT=${SEARXNG_PORT:-8080}
      - SEARXNG_BIND_ADDRESS=${SEARXNG_BIND_ADDRESS:-0.0.0.0}
      - SEARXNG_METHOD=${SEARXNG_METHOD:-POST}
    logging: *default-logging
    depends_on:
      valkey:
        condition: service_healthy
    healthcheck:
      test:
        - "CMD-SHELL"
        - "python3 -c 'import urllib.request; req = urllib.request.Request(\"http://localhost:8080/healthz\"); req.add_header(\"X-Forwarded-For\", \"127.0.0.1\"); urllib.request.urlopen(req)'"
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 512M
  cli-proxy-api-plus:
    image: ${CLI_PROXY_IMAGE:-eceasy/cli-proxy-api-plus:latest}
    container_name: cli-proxy-api-plus
    restart: unless-stopped
    networks:
      - backend-net
    depends_on:
      ollama:
        condition: service_healthy
      searxng:
        condition: service_healthy
    expose:
      - "8317"
    ports:
      - "54545:54545"
      - "51121:51121"
    environment:
      - DEPLOY=${DEPLOY:-}
    volumes:
      - ./cli-proxy-api-plus/config/config.yaml:/CLIProxyAPI/config.yaml
      - cli-proxy_auths:/root/.cli-proxy-api
      - ./cli-proxy-api-plus/logs:/CLIProxyAPI/logs
    logging: *default-logging
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8317/ || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M

networks:
  backend-net:


volumes:
  ollama_data:
    name: ollama_data
    labels:
      com.backup: "true"
      com.backup.exclude: "models"
      com.service: "ollama"
  caddy_data:
    name: caddy_data
    labels:
      com.backup: "true"
      com.service: "caddy"
  caddy_config:
    name: caddy_config
    labels:
      com.backup: "true"
      com.service: "caddy"
  searxng_data:
    name: searxng_data
    labels:
      com.backup: "true"
      com.service: "searxng"
  valkey_data:
    name: valkey_data
    labels:
      com.backup: "true"
      com.service: "valkey"
  cli-proxy_auths:
    name: cli-proxy_auths
    labels:
      com.backup: "true"
      com.service: "cli-proxy-api-plus"
